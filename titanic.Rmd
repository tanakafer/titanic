---
title: 'Tipología y ciclo de vida de los datos'
subtitle: 'Práctica 2'
author: "Fernando Rodríguez López"
date: "13/5/2019"
output:
  md_document:
    variant: markdown_github
  pdf_document:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    number_sections: true
geometry: left=3cm,right=3cm,top=2cm,bottom=2cm
#bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(ggplot2)
library(VIM)
library(mice)
library(randomForest)
library(ggpubr)
library(caret)
library(e1071)
library(nortest)
library(dummies)
```

# Descripción del dataset

El dataset seleccionada es el del hundimiento del titanic de Kaggle [https://www.kaggle.com/c/titanic/data]

El hundimiento del **RMS Titanic** es una de los hundimientos de barcos más famosos de la historia. El incidente
ocurrió entre el día 14 y 15 de abril de 1912. Durante su viaje inaugural entre Southampton y Nueva York, el transatlántico británico cochó contra un iceberg en el oceano Atlántico frente a las costas de Terranova.
Tras el choque el translatlántico se hundío y murieron 1502 personas de 2224 pasajeros y tribulates.

Esta tragedia ha sido una de las mayores tragedias naúticas en tipo de paz. Las causas del número de fallecidos fueron consecuencia de la falta de botes salvavidas. Pero además, en diferentes estudios se ha visto que la suerte de los supervivientes estaban realionadas con distintas características de los viajes y tripulantes. 

En el siguiente estudio se pretende ver que tipo de personas tuvieron la suerte de sobrevivir.  Teniendo en cuenta su género, clase social y edad. 

Los datos se han dividido en dos grupos:

- **El conjunto de entrenamiento** usado para crear el modelo de entrenamiento para un modelo. Para este grupo se le aporta la clase de salida (también conocidad como *ground truth*) 
- **El conunto de test** usado para comprobar lo bien que predice el modelo. En este grupo no se aporta la clase de salida. Sino que este grupo es utilizado para verificar los bien que modelo predice si un pasajero habría sobrevivido o no dependiendo de sus propiedades.

## Conjunto de entrenamiento 

El conjunto de entrenamiento es un fichero csv en código ASCII que consta de los siguiente atributos.
Este fichero incluye las cabeceras dentro del fichero y los campos están separados por ",".

|Variable         | Descripción         |Valores              |
|-----------------|---------------------|---------------------|
|PassengerId      |Identificador de pasajero|                     | 
|Survived 	      |Sobrevivió           |	0 = No, 1 = Sí      |
|pclass           |Tipo del billete 	  |1 = Primera clase, 2 = Segunda Clase, 3 = Tercera Clase|
|Name             |Nombre               |                     |
|Sex              |Género           	  |male = Hombre, female= Mujer|
|Age              |Edad en Años         |                     | 	
|Sibsp            |Número de familiares a bordo (hermanos, pareja)|                     | 	
|Parch            |Número de famliares a bordo (padres e hijos)	|                     | 	
|Ticket           |Número del billete	|                     |  	
|Fare             |Precio del billete|                     |  	
|Cabin            |Número de cabina |                     |  
|Embarked 	      |Puerto de embarque|C = Cherbourg, Q = Queenstown, S = Southampton|

## Conjuto de test

El conjuto de tes también es un fichero csv en código ASCII que consta de los siguientes atributos
Este fichero incluye las cabeceras dentro del fichero y los campos están separados por ",".

| Variable    | Descripción                                  | Valores                                                   |
|-------------|----------------------------------------------|-----------------------------------------------------------|
| PassengerId | Identificador del pasajero                   |                                                           |
| Pclass      | Tipo del billete                             | 1 = Primera clase,  2 = Segunda Clase,  3 = Tercera Clase |
| Name        | Nombre                                       |                                                           |
| Sex         | Género                                       | male = Hombre,  female= Mujer                             |
| Age         | Edad en Años                                 |                                                           |
| SibSp       | Número de familiares a bordo (hermanos, pareja)       |                                                  |
| Parch       | Número de famliares a bordo (padres e hijos) |                                                           |
| Ticket      | Número del billete                           |                                                           |
| Fare        | Precio del billete                           |                                                           |
| Cabin       | Número de cabina                             |                                                           |
| Embarked    | Puerto de embarque                           | C = Cherbourg, Q = Queenstown, S = Southampton            |


Para una mejor compresión del dataset tenemos que tener encuenta las siguientes consideraciones

**Age**: la edad en caso de viajeros que no superen más de un año es fraccional.

**SibsP**: Determina el númeor de familiares del tipo hermanos y pareja
  - Hermanos: incluye hermanos, hermanas, hermanástros y hermanástras
  - Pareja: esposos y esposas. Los novios y amantes fueron descartados
**Parch**: 
  - Padre:  madre y padre
  - Hijo: hijos, hijas, hijastros e hijastras.

# Integración y selección de los datos de interés a analizar

El primer paso que vamos a realizar es la carga de ambos ficheros  en un mismo dataframe. 
Como podemos comprobar los dos ficheros, tienen los mismos campos exceptuando  la clase de salida, que en el caso de conjunto test no existe. Ya que es el objeto de la competición de Kaggle.
Pero uniendo los dos ficheros en un dataframe único, podemos realizar un análisis y limpieza única con toda la población, observando datos perdidos, valores extremos y otros posibles errores.
Una vez realizado el trabajo de limpieza, podeos volver a separar para aplicar los modelos.

Hay que tener en cuenta que el archivo csv debe estar en el directorio "kaggle" dentro de nuestro directorio de trabajo. En caso contrario hay que especificar la ruta absoluta al archivo.

```{r Carga, message=FALSE, warning=FALSE}
# Leemos los datos de entrenamiento
train <- read.csv("./kaggle/train.csv")
# Leemos los datos de test
test <- read.csv("./kaggle/test.csv")

# Variable con las propiedades no incluyendo la clase salida
properties = colnames(test)
# Variable con la clase salida
class = c("Survived")
# Creamos un dataframe unico con todos los datos
titanic_raw <- bind_rows(train, test) 

# Creamos un dataframe donde realizamos las operaciones
titanic <- titanic_raw

```

Realizamos una comprobación visual, para ver si se han cargado los datos con las propiedades que hemos determinado en el apartado anterior.

```{r}
# Echamos un vistazo a los datos
str(titanic)
```

Observamos que hay 1309 que son la suma de los 418 elementos de test más los 891 elementos de entrenamiento que corresponde con la información que nos aporta kaggle.

## Clase de salida Survived

Todas estas observaciones tiene 12 propiedades, que corresponde a 11 atributos más la clase de salidad *Survived* donde los datos de test tendrían que tener el valor de NA.

Pero pasamos a comprobarlo.

```{r message=FALSE}
# Número de instancias con el valor Survived Nulo
str(titanic %>% filter(is.na(Survived)))
```
```{r message=FALSE}
#Comprobamos  que los PassengerID son los mismos en el dataframe titanic con Survived a NA y los de test
str(setdiff(test %>% select("PassengerId"), titanic %>% filter(is.na(Survived)) %>% select("PassengerId") ))
```


Como vemos el número de observaciones con Survived igual a NA corresponde al número de test y además no hay diferencias de los códigos de los pasajeros (PassengerId). Por lo que los NA corresponde a los datos del conjunto de test.

Así que hemos realizado correctamente la integración de los dos ficheros csv.


```{r factorized_Survice}
titanic$Survived <- as.factor(titanic$Survived)
levels(titanic$Survived)
```

## PassengerId

Ahora procedemos ha imprimir un resumen del dataframe para estudiar nuestra propiedades

```{r}
# Resumen de las propiedades sin contar la clase de salida
summary(titanic[properties])
```

El campo **PassengerId** es únicamente para identificar a cada uno de los pasajeros. Por lo que no formará parte de ninguno de nuestro estudios. Pero lo asignamos como el valor de **id** de nuestro Dataframe.

```{r}
# Asignamos el identificador de dataframe con los valores de PassengerId
rownames(titanic) <- titanic$PassengerId
# Eliminamos de la variable properties la variable
#titanic$PassengerId <- NULL
properties <- properties[!properties %in% "PassengerId"]
```


## Pclass

Vemos que la propiedad Pclass es numérica y debería de ser factor ya que no representa una categoricación numérica, además no tiene ningún valor perdido.

```{r Pclass}
titanic$Pclass <- factor(titanic$Pclass)
# Viajeros según la clase
  local({
   .Table <- with(titanic, table(Pclass))
   cat("\ncounts:\n")
   print(.Table)
   cat("\npercentages:\n")
   print(round(100*.Table/sum(.Table), 2))
   })
```

```{r}
with(titanic, plot(Pclass,Survived))
```
## Name -> Título

Revisando visualmente el campo **Name**(nombre) observamos que están los títulos de cada uno de los viajeros. Es decir si son señores, señoras, señorítas. Lo cual podría ser variable diferenciadora para determinar si se puede salvar o no.

Para ellos sacaremos el Título según los nombres

```{r}
# Cogemos los títulos según los nombres
titanic$Title <- gsub('(.*, )|(\\..*)', '', titanic$Name)
# Presentamos los anteriores títulos enfrentados al género
table(titanic$Sex, titanic$Title)
```

Procedemos a convertir los títulos obtenidos en un grupo más reducido
```{r}
# Titulos que vamos a convertir a Mr
toMr_title  <- c ('Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Sir')
# Convertirmos dichos títulos a Mr
titanic$Title[titanic$Title %in% toMr_title]  <- 'Mr'
# Titulos que vamos a convertir a Mrs
toMrs_title  <- c('the Countess', 'Mme', 'Dona', 'Lady')
# Convertirmos dichos títulos a Mr
titanic$Title[titanic$Title %in% toMrs_title]  <- 'Mrs'
# Titulos que vamos a convertir a Miss
toMiss_title  <- c('Mlle', 'Ms')
# Convertirmos dichos títulos a Miss
titanic$Title[titanic$Title %in% toMiss_title]  <- 'Miss'

# Convertimos los Dr - female en Mrs
titanic$Title[(titanic$Title %in% "Dr") & titanic$Sex == "female"] <- "Mrs"
# Convertimos los Dr - male en Mr
titanic$Title[(titanic$Title %in% "Dr") & titanic$Sex == "male"] <- "Mr"

# Añadimos  el atributo Title
properties <- append(properties, "Title")
# Show title counts by sex again
table(titanic$Sex, titanic$Title)

# Convertimos el campo en factor

titanic$Title <- as.factor(titanic$Title)
```
```{r}
# Viajeros según la Titulo
  local({
   .Table <- with(titanic, table(Title))
   cat("\ncounts:\n")
   print(.Table)
   cat("\npercentages:\n")
   print(round(100*.Table/sum(.Table), 2))
   })
```

```{r}
with(titanic, plot(Title,Survived))
```


Pero eliminamos el campos **Name** que no parece útil para ninguno de los posibles modelos.

```{r remove_Name}
# Eliminamos de la variable properties la variable
#titanic$Name <- NULL
properties <- properties[!properties %in% "Name"]
```
## Sex

El campo **Sex**(género) podría ser útil para nuestros modelos por lo que lo mantenemos.Y ya está como variable de tipo factor.

```{r Sex}

# Viajeros según el género
  local({
   .Table <- with(titanic, table(Sex))
   cat("\ncounts:\n")
   print(.Table)
   cat("\npercentages:\n")
   print(round(100*.Table/sum(.Table), 2))
   })
```

```{r}
with(titanic, plot(Sex,Survived))
```

## Age

El campo **Age**(edad) podría ser útil para nuestros modelos por lo que lo mantenemos, pero vemos que tiene valores perdídos que estudiaremos en el siguiente apartado.

```{r}
ggplot(titanic, aes(Age, fill = factor(Survived))) + 
  geom_histogram(bins=30) 
```


## Sibsp, Parch -> Family

Los dos siguientes atributos **Sibsp**(hermanos, pareja) y **Parch** (padres e hijos)	pueden ser interesantes para nuestros modelos, pero creemos que  podría ser válido para nuestros modelos la unión de los dos en un nuevo campo que sea **Familiy**.


```{r}
titanic$Family <- titanic$SibSp + titanic$Parch + 1
properties <- append(properties, "Family")
```

Es un atributo numérico, pero se puede considerar también cualitativo. 

```{r}
titanic$Family <- as.factor(titanic$Family)
with(titanic, plot(Family,Survived))
```
Como vemos en la gráfica, podemos observar que las familias con más 5 o más miembros tienen mucha probabilidad de no sobrevivir. Por otra parte los solteros  también tiene alta probabilidad de no sobrevivir y sin embargo  las familias con ménos de 5 miembros tienen alta probabilidad de sobrevivir.

Por ellos vamos a realizar una agrupación al campo **FamilyType** según estas agrupaciones.

```{r}
titanic$Family <- as.numeric(titanic$Family)
titanic$FamilyType <- 'Regular'
titanic$FamilyType[titanic$Family ==1]  <- 'Single'
titanic$FamilyType[titanic$Family >=5]  <- 'Large'

titanic$FamilyType <- ordered(titanic$FamilyType, c("Single", "Regular", "Large"))

titanic$FamilyType <- as.factor(titanic$FamilyType)
with(titanic, plot(FamilyType,Survived))



```
Este campo nuevo parece bastante interesante para poder discernir si un viajero tiene posibilidad de sobrevivir o no.

```{r}
# Añadimos este campo a la properties
properties = c(properties, "FamilyType")
# Eliminar Family, SibsSPy Parch
properties <- properties[!properties %in% c("Family", "SibSp", "Parch")]

```




## Ticket

El campo *Ticket* está como tipo characters, aunque no parece un campo útil, para nuestro modelo, pero vamos a convertirlo en factor, para ver si puede ser útil.

```{r Factorize_Ticket}
titanic$Ticket <- as.factor(titanic$Ticket)
# Hacemos un sumary
summary(titanic)
titanic %>% 
    group_by(Ticket) %>% 
    count()

```
Como podemos observar de los 1309 hay 1261 tipos distintos de Tickets, por lo tanto no parece un campo muy relevante y lo eliminamos de nuestro dataframe.

```{r remove_Ticket}
# Eliminamos de la variable properties la variable
#titanic$Ticket <- NULL
properties <- properties[!properties %in% "Ticket"]
```

## Fare

EL campo **Fare**(precio del billete) a priori parece interesante para un modelo de predicción de si el pasajero sobrevive o no. Vemos que tiene un valor perdido que también veremos en el próximo apartado.

```{r echo=FALSE}
ggplot(titanic, 
  aes(x = Fare)) +
  # Función de densidad de los valores de Fare filtrados
  geom_density(fill = '#99d6ff', alpha=0.4, na.rm=T) + 
  # Dibujamos la recta de la mediana
  geom_vline(aes(xintercept=median(Fare, na.rm=T)),
    colour='red', linetype='dashed', lwd=1) 
```
Observamos que hay muchos datos extremos, y nos hace plantearnos que el campo Fare es el precio del billete y es definido por el número de personas de dicho ticket.


## Cabin  -> Deck

EL campo **Cabin** (nombre del camarote) al igual que pasaba con Ticket no parece muy interesante para los modelos, pero vamos a factorizar.

```{r Factorize_Cabin}
titanic$Cabin <- as.factor(titanic$Cabin)
titanic %>% 
    group_by(Cabin) %>% 
    count()
```

```{r}
# Hacemos un sumary
summary(titanic[properties])
```

En el resumen vemos que hay 271 tipos de cabinas, por lo que parecería interesante ya que se agruparían muchos pasajeros, pero uno de los grupos contiene 1014 pasajeros. Por esto parece que no es muy interesante  pero agruparlos por las cubiertas de la cabina, para ver si es interesante dicha propiedad

```{r Deck}
titanic$Cabin <- as.character(titanic$Cabin)
titanic$Deck<-sapply(titanic$Cabin, function(x) strsplit(x, NULL)[[1]][1])
titanic$Deck[is.na(titanic$Deck)] <- "No Cabin"
titanic$Deck <- as.factor(titanic$Deck)
with(titanic, plot(Deck,Survived))
```
Este propiedad parece más interesante, porque  hay una probabilidad de 70% que si un pasajero no tuviera cabina, no sobreviviese.

```{r remove_Cabin}
# Eliminamos de la variable properties la variable
#titanic$Cabin <- NULL
properties <- properties[!properties %in% "Cabin"]
# Añadimos la variable Deck
properties <- c(properties, "Deck")
```



## Embarked

El último campo **Embarked**(puerto de embarque) es de tipo texto y lo pasamos a factor para ver si puede resultar interesante.

```{r Factorize_Embarked}
titanic$Embarked <- as.factor(titanic$Embarked)
titanic %>% 
    group_by(Embarked) %>% 
    count() 
```

De la agrupación vermos que tenemos 4 niveles y uno de ello es valor perdido, que estudiaremos en el próximo apartado.

Si analizamos los datos del embarque
```{r }

# Viajeros según el embarque
  local({
   .Table <- with(titanic, table(Embarked))
   cat("\ncounts:\n")
   print(.Table)
   cat("\npercentages:\n")
   print(round(100*.Table/sum(.Table), 2))
   })
```

```{r}
with(titanic, plot(Embarked,Survived))
```

De la gráfica podemos observar que parece que dependiendo de donde se realizase el embarque, hay variación de la probabilidad de sobrevivir por lo que parece un campo interesante de estudio.


# Limpieza de los datos.

## Valores vacios o que continen 0

Como hemos visto en el apartado anterior  de nuestras propiedades numéricas tenemos valores nulos en **Age** y **Fare** y de tipo factor en *Embarked*.

### Valor *Fare* con valor NA

Buscamos el único valor que contiene NA en su propiedad *Fare*

```{r}
titanic %>% filter(is.na(titanic$Fare))
```

De este pasajero observamos que su embarque fué en *Southampton* (‘S’) y es de tercera clase, que parece propiedades que determinarían el precio del embarque.

```{r}

ggplot(titanic[titanic$Pclass == '3' & titanic$Embarked == 'S', ], 
  aes(x = Fare)) +
  # Función de densidad de los valores de Fare filtrados
  geom_density(fill = '#99d6ff', alpha=0.4, na.rm=T) + 
  # Dibujamos la recta de la mediana
  geom_vline(aes(xintercept=median(Fare, na.rm=T)),
    colour='red', linetype='dashed', lwd=1) 
```

De esta visualización vemos que la mayoría de los valores se concentran cerca de la mediana, por lo que parece razonable sustituir el valor perdido con el valor de la mediana del grupo que corresponde con la misma clase y el mismo embarque.

```{r}
# Reemplazamos el valor perdido con el valor de la mediana
titanic$Fare[1044] <- median(titanic[titanic$Pclass == '3' & titanic$Embarked == 'S', ]$Fare, na.rm = TRUE)
sprintf ("Valor Fare reemplazado: %s", titanic$Fare[1044])
```


### Valor *Age* con valor NA


Como hemos visto los valores perdidos del atributo *Age* es de 263 que frente al total suponen un 20% que es una gran cantidad de valores perdidos.

```{r}
summary(titanic %>% select(properties) %>% filter(is.na(Age)))
```

Al ser un gran úmnero de valores, no podemos permitirnos elmininar dichos datos.

Para ello tenemos que imputar los posibles valores. Para ellos utilizaremos dos modelos uno el K vecinos y otro con un Random-forest según la biblioteca mice orientada para obtener rellenear valores vacios.

Primero con el KNN de la libería VIM.

```{r missing_knn, message=FALSE, warning=FALSE}

# La función kNN genera una nueva columna lógica que
# indica si se han imputado valores o no
mod_knn <- kNN(titanic, variable = ("Age"))

```

Con un Random Forest con la librería mice.

```{r message=FALSE, warning=FALSE}
set.seed(129)
mice_mod <- mice(titanic[, !names(titanic) %in% c('PassengerId','Name','Ticket','Cabin','Survived')], method='rf') 
mice_output <- complete(mice_mod)
```

Después de obtener los valores, con los dos métodos, representamos la función densidad, y la comparamos con los datos originales. Para valorar, como varía la función densidad de los datos con las imputaciones realizadas.

```{r}

# Función densidad de la Edad con los datos original
Age_original <- ggplot(titanic, 
  aes(x = Age)) +
  # Función de densidad de los valores de Age filtrados
  geom_density(fill = '#99d6ff', alpha=0.4, na.rm=T) + 
  # Dibujamos la recta de la mediana
  geom_vline(aes(xintercept=median(Age, na.rm=T)),
    colour='red', linetype='dashed', lwd=1) 
# Función densidad de la Edad con los datos completados con Knn
Age_knn <- ggplot(mod_knn, 
  aes(x = Age)) +
  # Función de densidad de los valores de Age filtrados
  geom_density(fill = '#99d600', alpha=0.4, na.rm=T) + 
  # Dibujamos la recta de la mediana
  geom_vline(aes(xintercept=median(Age, na.rm=T)),
    colour='red', linetype='dashed', lwd=1) 

# Función densidad de la Edad con los datos completados con Random-Forest según la libería mice

Age_rf <- ggplot(mice_output, 
  aes(x = Age)) +
  # Función de densidad de los valores de Age filtrados
  geom_density(fill = '#ff0f55', alpha=0.4, na.rm=T) + 
  # Dibujamos la recta de la mediana
  geom_vline(aes(xintercept=median(Age, na.rm=T)),
    colour='red', linetype='dashed', lwd=1) 

figure <- ggarrange(Age_original, Age_knn, Age_rf,
                    labels = c("Original", "Knn", "Random-Forest"),
                    ncol = 1, nrow =3)
figure

         
```

De la gráficas, observamos como el método **Random-Forest** obtiene una gráfica de densidad de la Edad muy parecida a la muestra original sin tener en cuenta los valores perdidos y la mediana no varía
Sin embargo, con el método **Knn** obtenemos una gráfica más distorsionada e incluso la mediana se desplaza un poco.
Por lo que procedemos a remplazar en nuestro dataframe los datos obtenidos con el método **Random-Forest** en los valores perdidos


```{r replace_RF}
# Reemplazamos los datos de la edad en nuestro dataframe original
titanic[,"Age"] <- mice_output$Age
```

### Valor *Embarked* con valor vacio

Presentamos los valores con embarque vacio
```{r empty_Embarked}
titanic %>% filter(Embarked == "")
```
Observamos que las instancias que tienen el embarque vacio son de la Clase 1 y tienen un precio de embarque de 80. 
Para ver como se distribuyen los precios de los embarques representamos los *boxplot* de la población según los embarques, descartando los elementos que tienen embarque vacio

```{r}
# Eliminamos de la población los que tiene embarque vacio
embark_fare <- titanic %>%
  filter(PassengerId != 62 & PassengerId != 830 & Pclass==1)
# Repesentamos los boxplot y una línea roja con el valor del precio del pasaje de los valores perdidos
ggplot(embark_fare, aes(x = Embarked, y = Fare)) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80), 
    colour='red', linetype='dashed', lwd=2) 
```

Como vemos la mediana de un embarque en Charbourg ('C') de primera clase coincide con el precio de 80 de la instancia que desconocemos el embarque por lo que parece razonable reemplazarlo por el valor de Charbourg

```{r missing_embarked}
titanic$Embarked[titanic$Embarked==""] <- "C"
titanic$Embarked <- as.factor(as.character(titanic$Embarked))
```


## Identificación y tratamiento de valores externos

Para detectar la presencia de valores atípicos examinaremos primero el resumen de los cinco números de Tukey, donde podremos observar un análisis descriptivo de los datos

Para obtener los datos sólo utilizaremos las variables numéricas **Age**,  **Fare**,  y la calculada **Family** a partir de **SibSp**, **Parch**.

```{r summary_outliers}
numeric_properties <- c ("Age",  "Fare", "Family")
summary(titanic %>% select(numeric_properties))
```
 Los cinco números también  se representan gráficamente con **boxplot**
```{r}
sapply(titanic[numeric_properties], boxplot.stats)
```
 

### Age
 Para estudiar los valores extremos dibujamos el boxplot de la propiedad
```{r Age_box}
Age_boxplot <- ggplot(titanic, aes(x="", y=Age) ) +
  geom_boxplot() 
Age_boxplot
```


De la gráfica, observamos que la mayoría de la población se encuentra entre 0 y 60 años aproximadamente. Pero hay pasajeros que se encuentra entre los 60 y los 80 años. Por lo que no parece que hay errores tipográficos, y parecen valores razonables ya que no hay ninguna edad que pueda ser considerada erronea.

```{r}
titanic$AgeType[titanic$Age < 18] <- "Child"
titanic$AgeType[titanic$Age >= 18 & titanic$Age < 65] <- "Adult"
titanic$AgeType[titanic$Age >= 65] <- "Elder"
titanic$AgeType <- ordered(titanic$AgeType, c("Child", "Adult", "Elder"))
```
```{r}
# Viajeros según el embarque
  local({
   .Table <- with(titanic, table(AgeType))
   cat("\ncounts:\n")
   print(.Table)
   cat("\npercentages:\n")
   print(round(100*.Table/sum(.Table), 2))
   })
```

```{r}

with(titanic, plot(AgeType,Survived))
```
```{r}
#Eliminaos la propiedad Age
properties <- properties[!properties %in% "Age"]
# Añadimos la variable Deck
properties <- c(properties, "AgeType")
```



### Fare

```{r}
Fare_boxplot <- ggplot(titanic, aes(x="", y=Fare)) +
  geom_boxplot() 
Fare_boxplot
```
De las observación de las gráficas, no podemos observar valores extremos que se puedan considerar erroneos.
Pero parece razonable que los precios corresponda con el tipo de clase. Por lo que ahora haremos un gráfico  de boxplot catalogados por clase.

```{r Fare_boxplot_Pclass}
Fare_boxplot_Pclass <- ggplot(titanic, aes(x=Pclass, y=Fare)) +
  geom_boxplot() 
Fare_boxplot_Pclass
```

Para verificar, los valores extremos podemos calcular el precio por persona y relacionarlo con la clase.

```{r}
# Calculamos el número de pasajeros por ticket
titanic$person_per_ticket <- sapply(titanic$Ticket,
                      function(x) nrow(subset(titanic, Ticket==x)))
# Calculamos el precio por pasajero
titanic$Fare_per_person=titanic$Fare/titanic$person_per_ticket
```


```{r}
# Representams el boxplot del precio por pasajero frente a la clase
Fare_per_person_boxplot_Pclass <- ggplot(titanic, aes(x=Pclass, y=Fare_per_person)) +
  geom_boxplot() 
Fare_per_person_boxplot_Pclass
```

En esta gráfica del precio por persona del billete, observamos una mayor diferencia de los precios por la clase del billete. 
Aun habiendo precios que son valores extremos, se puede ver que los rangos por cada clase son razonables. Ya que por el precio del billete en el mayoría de los casos se podría determinar a que clase pertenece.

Por lo que parece más razonable utilizar esta variable calculada **Fare_per_person** que la original.


```{r include=FALSE}
# Añadimos Fare_per_person como posible varible para sustituir por el Fare
properties <- c(properties, "Fare_per_person")
properties <- properties[!properties %in% "Fare"]
numeric_properties <- c(numeric_properties, "Fare_per_person")
numeric_properties <- numeric_properties[!numeric_properties %in% "Fare"]
```


### Family

```{r}
Family_boxplot <- ggplot(titanic, aes(x="", y=Family)) +
  geom_boxplot() 
Family_boxplot
```

De los datos observamos que hay valore extremos, pero estos valores no parecen erroneos ya que la mayoría de los pasajeros son solteros y hay distintos tipos de familia que van desde los dos miembros hasta los 11 miembros de familia numerosa. Por tanto nuestro campo **FamilyType** calculado también es correcto.





# Análisis de los datos.


## Selección de los grupos de datos que se quieren analizar/comparar

En nuestro caso, el objetivo es detectar las variables que más contribuyen a explicar si un viajero va a sobrevivir o no, por lo que tendremos que  generar un modelo predictivo y/o de clasificación para ubicar a un viajeros según alguna de sus características.

Nuestro dataset ya se nos ha dado en dos conjuntos, uno para estudio y otro para dar solución al problema que se plantea en Kaggle. Estos  son los que tenemos un valor en la clase de salidad **Survived**.

Para hacer el estudio separaremos el primer conjunto en dos uno para entrenamiento y otro para test. 
La separación la realizaremos en 80% para training y 20% para test.
Y el tercer grupo será para dar los resultado .
```{r splitdata}
# Separamos los datos
notsubmission <- titanic %>% filter(not(is.na(Survived)))
index <- createDataPartition(notsubmission$PassengerId, p = 0.8, list = FALSE)

train <- notsubmission[index,]
test <- notsubmission[-index,]

rownames(train) <- train$PassengerId
rownames(test) <- test$PassengerId


# Datos de  entrega
submission <- titanic %>% filter(is.na(Survived))
rownames(submission) <- submission$PassengerId
```


## Comprobación de la normalidad y homogeneidad de la varianza.

Para el estudio de la normalidad y homogeneidad de la varianza en nuestro conjunto utilizaremos el test de normalidad de Anderson-Darling, que básicamente realiza el siguiente contraste de hipótesis:

- H0: No hay diferencias observables entre los datos y la distribución normal
- H1: Existen diferencias observables entre los datos y la distribución normal

```{r Anderson_Darling}

sapply(train[c(numeric_properties)], ad.test)

```
Si nos fijamos en los valores de p de todos los atributos y asignamos el valor de significación de 0,05 , observamos que todos ellos son valores muy por debajo del valor de significación. Por tanto no se puede aceptar la hipótesis nula. Por lo que podemos afirmar con un 95 % de fiabilidad que **los datos no siguen una distribución normal**.

Podríamos también aplicar el test de normalidad de Shapiro-Wilk.

```{r Saphiro_Wilk}
sapply(train[c(numeric_properties)], shapiro.test)
```

Observando igualmente que nuestros valores **no siguen una distribución normal**.


Como ninguna de nuestras variables siguen una distribución normal, para realizar el estudio la homogeneidad de las varianzas, utilizaremos el test de Fligner-Killeen, que compara las varianzas basándose en la mediana.
Donde 
-H0: la varianza es igual entre los grupos
-H1: la varianza no es igual entre los grupos

```{r Fligner-Killeen-AGE}
train$SurvivedNumeric <- 0 
train$SurvivedNumeric[train$Survived ==1]<- 1
test$SurvivedNumeric <- 0 
test$SurvivedNumeric[test$Survived ==1]<- 1
fligner.test(SurvivedNumeric ~ Family, data = train)
```
A un 95% de confianza la varianzas **no son iguales** entre los grupos


```{r Fligner-Killeen-Family}
fligner.test(SurvivedNumeric ~ Fare_per_person, data = train)
```
A un 95% de confianza la varianzas ** son iguales** entre los grupos

```{r Fligner-Killeen-Fare}
fligner.test(SurvivedNumeric ~ Age, data = train)
```

A un 95% de confianza la varianzas **son iguales** entre los grupos

## Aplicación de pruebas estadísticas para comparar los grupos de dato

Para el siguiente estudio nos quedaremos con las propiedades Pclass, Sex, AgeType, Embarked , Title, FamilyType, Deck, Fare_per_person.

De las cuales una es numéricas Fare_per_person y el resto son categóricas

```{r include=FALSE}
numeric_properties <- c("Fare_per_person")
```

Aunque podríamos utilizar otras dos variables que serían Family o Age si el modelo requiera valores numéricos.

### Análisis de correlacción

Nuestra primera prueba estadística será la de estudiar cuál de nuestras variables tiene mayor repercusión sobre la variable dependiente. 
Para hacer el análisis utilizaremos las variables numéricos Family, Age y Fare_per_person y las categóricas Pclass, Sex, Embarked y title.
Para realizar el análisis de correlación tendremos que crear variables dummies para las variables categócias.
Utilizaremos el coeficiente de correlación de pearson y un nivel de corte de correlación de 0.7.

```{r}
train_CM <-  dummy.data.frame(train[c("SurvivedNumeric","Pclass", "Sex", "Embarked", "Title","Family" ,"Deck", "Age"      , "Fare_per_person")], sep = ".")

test_CM <-  dummy.data.frame(test[c("SurvivedNumeric","Pclass", "Sex", "Embarked", "Title","Family" ,"Deck", "Age"      , "Fare_per_person")], sep = ".")

CM <- cor(train_CM)
highlyCorrelated <-  findCorrelation(CM, cutoff = 0.7 , names = TRUE)
c(highlyCorrelated)
```
Como vemos las variables es más correladas están son todas categóricas. 

### Modelo de regresión lineal (logit)

Crearemos un modelo de regresión lineal con los  predictores anteriores, usando el conjunto de entrenamiento (*train*). Para su evaluación, se usará el *test*.
Como son categóricas utilizaremos con base los elementos que tenemos mayor correlación.

```{r}
logitMod <- glm(SurvivedNumeric ~ Pclass.1 + Pclass.2 + Title.Mr + Title.Miss  + Title.Mrs + Sex.female + Embarked.C + Embarked.Q , data=train_CM, family=binomial(link="logit"))

summary(logitMod)
```
Vemos que estadísticamente los más relevantes son las Clase 1 y 2 junto con el título de Mr.

Se hace notar que la variable Sex.female no está definida. Esto es consecuencia en que hay otra variable que está altamente relacionada con Sex. Si presentamos los datos  de la matriz de correlación vemos que hay una correlación alta con Tittle.Mr.

```{r}
CM["Sex.female",]
```
Por lo que podríamos eliminar una de las dos variables. Por ejemplo Sex.female

```{r}
logitMod <- glm(SurvivedNumeric ~ Pclass.1 + Pclass.2 + Title.Mr + Title.Miss  + Title.Mrs  + Embarked.C + Embarked.Q , data=train_CM, family=binomial(link="logit"))

summary(logitMod)
```

Para obtener una métrica del modelo según los datos de entrenamiento

```{r}
logitModPredTrain <- predict(logitMod, type = "response")
logitCMTrain <- table(train_CM$Survived, logitModPredTrain >= 0.5)
logitCMTrain
```
```{r}

logitAccuracy <- local( function(table) { 
  total <- table[1,1] +table[1,2]+table[2,1]+table[2,2]
  accuracy <- (table[2,2]+ table[1,1]) / total
  accuracy
})
logitSensitivity <- local( function(table) { 
  sensitivity <- table[2,2] / (table[2,2] + table[2,1])
  sensitivity
})
logitSpecificity <- local( function(table) { 
  specificity <- table[1,1] / (table[1,1] + table[1,2])
  specificity
})  

logit_accuracy_train <- logitAccuracy(logitCMTrain)
cat ("Accuracy train:" , logit_accuracy_train)
```


```{r}
logitModPredTest <- predict(logitMod, type = "response", newdata = test_CM)
logitCMTest <-table(test_CM$Survived, logitModPredTest >= 0.5)
logitCMTest

```
```{r}
logit_accuracy_test <- logitAccuracy(logitCMTest)
cat ("Accuracy test:" , logit_accuracy_test)
```


### Modelo de clasificación con Random-forest

Como la mayoría de las variables que tenemos las hemos categorizado, una modelo de clasificación que podríamos optar es por un Random-forest.

```{r rf}
x_rf_train <- train[c(properties)]
y_rf_train <- train$Survived
rf <- C50::C5.0( x_rf_train, y_rf_train)
summary(rf)
```

Como vemos el error es de casi un 16%, teniendo una precisión del 84% que es bastante bueno.

También observamos que los falsos negativos, es decir personas que nuestro modelo determina que no sobrevive, pero si lo hace es de 39 que no supone ni un 5%.
Los falsos positivos, es un poco más alto llegando al 11%.


Ahora hacemos la predicción

```{r}
x_rf_test <- test[properties]
y_rf_test = predict(rf, newdata = x_rf_test)
x_rf_test$Survived<- y_rf_test

```



### SVM

Otro modelo que podemos utilizar para predecir la supervivencia de un viajero sería SVM ( Support Vector Machine). 
Como la mayoría de nuestras propiedades son categóricas tendríamos que utilizar un valor dummy para aquellas que no la hayamos obtenido de la numérica.
Para el caso de Age y Family utilizaremos la versión numérica en vez de la categórica

```{r}
train_SVM <- dummy.data.frame(train[c("Pclass", "Sex", "Age", "Embarked" , "Title", "Family", "Deck", "Fare_per_person")], sep = ".")
train_SVM$Survived <- train$Survived
```

```{r message=TRUE, warning=TRUE}
trainControl <- trainControl(method="repeatedcv", number=10, repeats=3)
metric <- "Accuracy"
grid <- expand.grid(.sigma=c(0.025, 0.05, 0.1, 0.15), .C=seq(1, 10, by=1))
fit.svm <- train(Survived~., data=train_SVM, method="svmRadial", metric=metric, tuneGrid=grid,
preProc=c("BoxCox"), trControl=trainControl, scale = FALSE )
print(fit.svm)
```



# Representación de los resultados a partir de tablas y gráficas. 

# Resolución del problema
# Código
 
El código se encuentra disponible en

[https://github.com/tanakafer/titanic](https://github.com/tanakafer/titanic)

# Dataset


# Contribuciones

| Contribuciones | Firma |
|----------------|-------|
| Investigación previa| [FRL](https://github.com/tanakafer)|
| Redacción de las respuestas | [FRL](https://github.com/tanakafer)|
| Desarrollo código | [FRL](https://github.com/tanakafer) |

# References

